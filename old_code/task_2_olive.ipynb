{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 2 \n",
    "\n",
    "\n",
    "### Task 2.1\n",
    "Get list of US politicians with political affiliation. \n",
    "\n",
    "2 sources:\n",
    "- https://github.com/casmlab/politicians-tweets \n",
    "- https://www.congress.gov/members?q={%22congress%22:[%22110%22,%22111%22,%22112%22,%22113%22,%22114%22,%22115%22,%22116%22,117]}\n",
    "\n",
    "Take 1st list, keep politicians whose affiliation is known. Then merge with congress list to be sure we have a good dataset.\n",
    "List of politicians is in `data/ressources/politicians.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import bz2\n",
    "\n",
    "# from tqdm.contrib.concurrent import process_map\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "# tqdm for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config part\n",
    "DATA_PATH = \"data\"\n",
    "PKL_PATH = os.path.join(DATA_PATH, \"pkl\")\n",
    "RESOURCES_PATH = os.path.join(DATA_PATH, \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(\n",
    "    file_name: str, mode: str = \"pandas\", save: bool = True, chunksize: int = 1_000_000\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a dataset in DataFrame from a .json.bz2 archive.\n",
    "\n",
    "    file_name: str\n",
    "        Name of .json.bz2 archive to load from `DATA_PATH`.\n",
    "\n",
    "    mode: str = \"pandas\" | \"bz2\"\n",
    "        Either use pandas read_json function or homemade bz2 function. This is usually faster (but makes my computer crash for some reason).\n",
    "\n",
    "    save: bool\n",
    "        Save the dataframe as a pickle file in `PKL_PATH`.\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = os.path.join(DATA_PATH, file_name)\n",
    "\n",
    "    if mode == \"bz2\":\n",
    "        keys = [\"quoteID\", \"quotation\", \"speaker\", \"date\", \"numOccurrences\", \"phase\"]\n",
    "\n",
    "        with bz2.open(file_path, \"rb\") as quote_file:\n",
    "            df = pd.DataFrame(\n",
    "                [\n",
    "                    dict(zip(keys, map(json.loads(instance).get, keys)))\n",
    "                    for instance in tqdm(quote_file)\n",
    "                ]\n",
    "            )\n",
    "    else:\n",
    "        if not save:\n",
    "            print(\"Please enable save option.\")\n",
    "            return\n",
    "\n",
    "        with pd.read_json(file_path, lines=True, chunksize=chunksize) as df_reader:\n",
    "            for i, chunk in enumerate(df_reader):\n",
    "                file_name = file_name.strip(\".json.bz2\")\n",
    "                pkl_path = os.path.join(PKL_PATH, f\"{file_name}-{i:03d}.pkl\")\n",
    "                chunk.to_pickle(pkl_path)\n",
    "\n",
    "                if i == 1:\n",
    "                    break\n",
    "        return\n",
    "\n",
    "    file_name = file_name.strip(\".json.bz2\")\n",
    "    pkl_path = os.path.join(PKL_PATH, f\"{file_name}.pkl\")\n",
    "\n",
    "    if save and not os.path.exists(pkl_path):\n",
    "        df.to_pickle(os.path.join(PKL_PATH, pkl_path))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(file_name: str, pol_lst: list) -> None:\n",
    "    \"\"\"\n",
    "    Write list to csv.\n",
    "    \"\"\"\n",
    "\n",
    "    csv_path = os.path.join(\"data\", \"resources\", file_name)\n",
    "\n",
    "    with open(csv_path, \"w\") as f:\n",
    "        writer = csv.writer(f, delimiter=\" \")\n",
    "        writer.writerow([\"Name\", \"Party\"])\n",
    "\n",
    "        for member in pol_lst:\n",
    "            writer.writerow([el for el in member])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pkl_year(year: int) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of the pkl files present in `data/pkl/{year}`.\n",
    "    \"\"\"\n",
    "\n",
    "    dirs = os.listdir(os.path.join(PKL_PATH, str(year)))\n",
    "\n",
    "    return [os.path.join(str(year), dir) for dir in dirs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Github dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"politicians_github.json\"\n",
    "file_path = os.path.join(\"data\", \"resources\", file_name)\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'id_str', 'screen_name', 'confirmed_account_type', 'state', 'twitter_name', 'real_name', 'bioguide', 'office_holder', 'party', 'district', 'level', 'woman', 'birthday', 'last_updated'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9979/9979 [00:00<00:00, 311395.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Only keep politicians with political affiliation\n",
    "politicians = []\n",
    "\n",
    "for i in tqdm(range(1, len(json[\"id\"]))):\n",
    "    i = str(i)\n",
    "    affiliation = json[\"party\"][i]\n",
    "    screen_name = json[\"screen_name\"][i]\n",
    "    elected = json[\"office_holder\"][i] is not None\n",
    "\n",
    "    if affiliation is not None and affiliation in (\"Republican\", \"Democratic\"):\n",
    "        politicians.append((json[\"real_name\"][i], affiliation, elected))\n",
    "    elif screen_name == \"realdonaldtrump\":\n",
    "        politicians.append((\"Donald Trump\", \"Republican\", True))\n",
    "    elif screen_name == \"barackobama\":\n",
    "        politicians.append((\"Barack Obama\", \"Democratic\", True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many politicians are \"elected\" (-> congress members)\n",
    "sum(pol[-1] for pol in politicians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All politicians are in Congress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(politicians)=1107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Mark Green', 'Republican', True),\n",
       " ('Pete Stauber', 'Republican', True),\n",
       " ('Derek Kilmer', 'Democratic', True),\n",
       " ('Andy Harris', 'Republican', True),\n",
       " ('Donald Payne', 'Democratic', True),\n",
       " ('A. Ferguson', 'Republican', True),\n",
       " ('Richard Hudson', 'Republican', True),\n",
       " ('Edward Markey', 'Democratic', True),\n",
       " ('Bobby Rush', 'Democratic', True),\n",
       " ('Gregory Meeks', 'Democratic', True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(f\"{len(politicians)=}\") \n",
    "politicians[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "to_csv(\"politicians_github.csv\", politicians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### US Congress dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.congress.gov/members?q={\"congress\":[\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",117]}&pageSize=250'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Strip and clean name.\n",
    "    \"Senator Cruz, Ted\" -> \"Ted Cruz\"\n",
    "    \"\"\"\n",
    "\n",
    "    for element in (\"Representative\", \"Senator\"):\n",
    "        name = name.strip(element)\n",
    "\n",
    "    name = \" \".join(name.split(\",\")[::-1])\n",
    "    name = name.strip()\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.07s/it]\n"
     ]
    }
   ],
   "source": [
    "congress_members = []\n",
    "\n",
    "# Download each congress page\n",
    "with requests.Session() as s:\n",
    "    for page_number in tqdm(range(1, 6)):\n",
    "        r  = s.get(URL, params={\"page\": page_number})\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        members = soup.find_all(\"li\", class_=\"compact\")\n",
    "\n",
    "        for member in members:\n",
    "            # Scrape the information\n",
    "            items = member.find_all(\"span\", class_=\"result-item\")\n",
    "            name = sanitize_name(member.span.a.text)\n",
    "            \n",
    "            for item in items:\n",
    "                if item.strong.text == \"Party:\":\n",
    "                    affiliation = item.span.text\n",
    "\n",
    "            congress_members.append((name, affiliation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "len(congress_members) == 1158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "to_csv(\"politicians_congress.csv\", politicians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually might not be useful (and less of a headache) to just take the congress list, since all politicians from the github list are elected (meaning they are or were congress members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 - Extract quotes from politicians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded another list, from the congress [website](https://bioguide.congress.gov/search?index=%22bioguideprofiles%22&size=12&matches=[]&filters={%22jobPositions.congressAffiliation.partyAffiliation.party.name%22:[%22Democrat%22,%22Republican%22],%22jobPositions.congressAffiliation.congress.name%22:[%22The%20110th%20United%20States%20Congress%22,%22The%20111th%20United%20States%20Congress%22,%22The%20112th%20United%20States%20Congress%22,%22The%20113th%20United%20States%20Congress%22,%22The%20114th%20United%20States%20Congress%22,%22The%20115th%20United%20States%20Congress%22,%22The%20116th%20United%20States%20Congress%22,%22The%20117th%20United%20States%20Congress%22]}&sort=[{%22_score%22:true},{%22field%22:%22familyName%22,%22order%22:%22asc%22},{%22field%22:%22middleName%22,%22order%22:%22asc%22},{%22field%22:%22givenName%22,%22order%22:%22asc%22}])\n",
    "\n",
    "\n",
    "Those are the politicians from 2007 to 2009. The json is called `data/resources/congress_biolist.json`. What is nice is that we have the \"congress bio ID\" of each congress member, which is also present in the `speaker_attributes.parquet` file (field `US_congress_bio_ID`). We will use that to extract the tweets from the politicians.\n",
    "\n",
    "Testing with quotes from 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians_filepath = os.path.join(RESOURCES_PATH, \"congress_biolist.json\")\n",
    "# quotes_filepath = os.path.join(DATA_PATH, \"quotes-2008.json.bz2\")\n",
    "# keys = ['quoteID', 'quotation', 'speaker', 'date', 'numOccurrences', 'phase']\n",
    "\n",
    "politicians_df = pd.read_json(politicians_filepath)\n",
    "# politicians_df = politicians_df.drop(\"congresses\", axis=1)\n",
    "# quotes_df = pd.read_pickle(os.path.join(PKL_PATH, \"quotes-2008.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Donald Trump is not in the dataset (because he was only President, not senator or representative and thus, not a congress member). I will manually add him now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2020_00 = pd.read_pickle(os.path.join(PKL_PATH, \"2020\", \"quotes-2020-000.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Donald Trump', 'President Donald Trump', 'President Trump',\n",
       "       'Melania Trump', 'Eric Trump', 'Ivanka Trump',\n",
       "       'Donald Trump Jr. .', 'Donald Trump Jr', 'Donald Trump , Jr. .',\n",
       "       'Donald J. Trump', 'President Donald J. Trump', 'Barron Trump',\n",
       "       'president Donald Trump', 'Lara Trump', 'DONALD Trump',\n",
       "       'Donald J Trump', 'PRESIDENT Donald Trump', 'president Trump',\n",
       "       'Donald John Trump', 'PRESIDENT Trump'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_2020_00[quotes_2020_00[\"speaker\"].str.contains(\"Trump\")][\"speaker\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add Donald Trump\n",
    "# Not so elegant trick to capture variations of the name\n",
    "# Should refactore to another solution (alias field?) when we have time\n",
    "\n",
    "donald_json1 = {\n",
    "    \"id\": np.nan,\n",
    "    \"givenName\": \"Donald\",\n",
    "    \"familyName\": \"Trump\",\n",
    "    \"unaccentedGivenName\": \"Donald\",\n",
    "    \"unaccentedFamilyName\": \"Trump\",\n",
    "    \"birthYear\": 1946,\n",
    "    \"deathYear\": np.nan,\n",
    "    \"congresses\": [\n",
    "        {\n",
    "            \"position\": \"President\",\n",
    "            \"congressNumber\": np.nan,\n",
    "            \"stateName\": np.nan,\n",
    "            \"parties\": [\"Republican\"],\n",
    "        }\n",
    "    ],\n",
    "    \"middleName\": \"John\",\n",
    "    \"unaccentedMiddleName\": \"John\",\n",
    "    \"nickName\": np.nan,\n",
    "    \"honorificPrefix\": np.nan,\n",
    "    \"honorificSuffix\": np.nan,\n",
    "}\n",
    "\n",
    "donald_json2 = {\n",
    "    \"id\": np.nan,\n",
    "    \"givenName\": \"President\",\n",
    "    \"familyName\": \"Trump\",\n",
    "    \"unaccentedGivenName\": \"President\",\n",
    "    \"unaccentedFamilyName\": \"Trump\",\n",
    "    \"birthYear\": 1946,\n",
    "    \"deathYear\": np.nan,\n",
    "    \"congresses\": [\n",
    "        {\n",
    "            \"position\": \"President\",\n",
    "            \"congressNumber\": np.nan,\n",
    "            \"stateName\": np.nan,\n",
    "            \"parties\": [\"Republican\"],\n",
    "        }\n",
    "    ],\n",
    "    \"middleName\": \"John\",\n",
    "    \"unaccentedMiddleName\": \"John\",\n",
    "    \"nickName\": np.nan,\n",
    "    \"honorificPrefix\": np.nan,\n",
    "    \"honorificSuffix\": np.nan,\n",
    "}\n",
    "\n",
    "donald_json3 = {\n",
    "    \"id\": np.nan,\n",
    "    \"givenName\": \"President Donald\",\n",
    "    \"familyName\": \"Trump\",\n",
    "    \"unaccentedGivenName\": \"President Donald\",\n",
    "    \"unaccentedFamilyName\": \"Trump\",\n",
    "    \"birthYear\": 1946,\n",
    "    \"deathYear\": np.nan,\n",
    "    \"congresses\": [\n",
    "        {\n",
    "            \"position\": \"President\",\n",
    "            \"congressNumber\": np.nan,\n",
    "            \"stateName\": np.nan,\n",
    "            \"parties\": [\"Republican\"],\n",
    "        }\n",
    "    ],\n",
    "    \"middleName\": \"John\",\n",
    "    \"unaccentedMiddleName\": \"John\",\n",
    "    \"nickName\": np.nan,\n",
    "    \"honorificPrefix\": np.nan,\n",
    "    \"honorificSuffix\": np.nan,\n",
    "}\n",
    "\n",
    "politicians_df = politicians_df.append(\n",
    "    pd.DataFrame([donald_json1, donald_json2, donald_json3]), ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>givenName</th>\n",
       "      <th>familyName</th>\n",
       "      <th>unaccentedGivenName</th>\n",
       "      <th>unaccentedFamilyName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>congresses</th>\n",
       "      <th>middleName</th>\n",
       "      <th>unaccentedMiddleName</th>\n",
       "      <th>nickName</th>\n",
       "      <th>honorificPrefix</th>\n",
       "      <th>honorificSuffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>Z000017</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Zeldin</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Zeldin</td>\n",
       "      <td>1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'position': 'Representative', 'congressNumbe...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>Z000018</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Zinke</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Zinke</td>\n",
       "      <td>1961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'position': 'Representative', 'congressNumbe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'position': 'President', 'congressNumber': n...</td>\n",
       "      <td>John</td>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>NaN</td>\n",
       "      <td>President</td>\n",
       "      <td>Trump</td>\n",
       "      <td>President</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'position': 'President', 'congressNumber': n...</td>\n",
       "      <td>John</td>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>President Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>President Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'position': 'President', 'congressNumber': n...</td>\n",
       "      <td>John</td>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         givenName familyName unaccentedGivenName  \\\n",
       "1153  Z000017               Lee     Zeldin                 Lee   \n",
       "1154  Z000018              Ryan      Zinke                Ryan   \n",
       "1155      NaN            Donald      Trump              Donald   \n",
       "1156      NaN         President      Trump           President   \n",
       "1157      NaN  President Donald      Trump    President Donald   \n",
       "\n",
       "     unaccentedFamilyName  birthYear  deathYear  \\\n",
       "1153               Zeldin       1980        NaN   \n",
       "1154                Zinke       1961        NaN   \n",
       "1155                Trump       1946        NaN   \n",
       "1156                Trump       1946        NaN   \n",
       "1157                Trump       1946        NaN   \n",
       "\n",
       "                                             congresses middleName  \\\n",
       "1153  [{'position': 'Representative', 'congressNumbe...          M   \n",
       "1154  [{'position': 'Representative', 'congressNumbe...        NaN   \n",
       "1155  [{'position': 'President', 'congressNumber': n...       John   \n",
       "1156  [{'position': 'President', 'congressNumber': n...       John   \n",
       "1157  [{'position': 'President', 'congressNumber': n...       John   \n",
       "\n",
       "     unaccentedMiddleName nickName honorificPrefix honorificSuffix  \n",
       "1153                    M      NaN             NaN             NaN  \n",
       "1154                  NaN      NaN             NaN             NaN  \n",
       "1155                 John      NaN             NaN             NaN  \n",
       "1156                 John      NaN             NaN             NaN  \n",
       "1157                 John      NaN             NaN             NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politicians_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export new df to json\n",
    "politicians_df.to_json(os.path.join(RESOURCES_PATH, \"new_congress_biolist.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians_df[\"fullName\"] = politicians_df[\"givenName\"] + \" \" + politicians_df[\"familyName\"]\n",
    "politicians_df[\"fullName\"] = politicians_df[\"fullName\"].str.lower()\n",
    "\n",
    "congress_members = politicians_df[\"fullName\"].tolist()  # redefined here for clarity\n",
    "\n",
    "def extract_subset(orig_df: pd.DataFrame, multiproc=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function extracts the quotes of speakers that are in the congress list.\n",
    "\n",
    "    It returns the number of extracted quotes and the extracted dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    if multiproc:\n",
    "        orig_df[\"subset\"] = orig_df[\"speaker\"].parallel_apply(\n",
    "            lambda x: pd.Series(x.lower()).str.contains(\"|\".join(congress_members))\n",
    "        )\n",
    "    else:\n",
    "        orig_df[\"subset\"] = orig_df[\"speaker\"].progress_apply(\n",
    "            lambda x: pd.Series(x.lower()).str.contains(\"|\".join(congress_members))\n",
    "        )\n",
    "\n",
    "    return orig_df[\"subset\"].sum(), orig_df[orig_df[\"subset\"] == True]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% subset\n",
    "quotes_2020_00 = quotes_2020_00.sample(int(0.1*len(quotes_2020_00)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:47<00:00, 1061.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Testing multiprocessing for extraction\n",
    "subset_count, subset_2020 = extract_subset(quotes_2020_00)\n",
    "subset_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "President Donald Trump    266\n",
       "President Trump           125\n",
       "Donald Trump               73\n",
       "Elizabeth Warren           72\n",
       "Mike Pompeo                65\n",
       "                         ... \n",
       "John kerry                  1\n",
       "Nikema Williams             1\n",
       "Michael Fitzpatrick         1\n",
       "Virginia Foxx               1\n",
       "Vicky Hartzler              1\n",
       "Name: speaker, Length: 344, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_2020[\"speaker\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/pkl/quotes-2008.pkl',\n",
       " 'data/pkl/quotes-2009.pkl',\n",
       " 'data/pkl/quotes-2010.pkl',\n",
       " 'data/pkl/quotes-2011.pkl',\n",
       " 'data/pkl/quotes-2012.pkl',\n",
       " 'data/pkl/quotes-2013.pkl',\n",
       " 'data/pkl/quotes-2014.pkl',\n",
       " 'data/pkl/quotes-2015.pkl',\n",
       " 'data/pkl/quotes-2016.pkl',\n",
       " 'data/pkl/quotes-2017.pkl',\n",
       " 'data/pkl/quotes-2018.pkl',\n",
       " 'data/pkl/quotes-2019.pkl',\n",
       " 'data/pkl/quotes-2020.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goal is to do a pipeline to automatically extract quotes for a quotes dataset\n",
    "# The datasets were already loaded from the json.bz2 format and converted to .pkl in `data/pkl`\n",
    "\n",
    "# Get the names\n",
    "quotes_datasets = [os.path.join(\"data\", \"pkl\", f\"quotes-20{i:02d}.pkl\") for i in range(8, 21)]  \n",
    "\n",
    "# For each dataset, extract the quotes from congress members\n",
    "# and save the extracted quotes as pkl for easier handling\n",
    "for i, dataset in enumerate(quotes_datasets, start=1):\n",
    "    print(f\"{i}/{len(quotes_datasets)} {dataset}:\")\n",
    "    try:\n",
    "        complete_df = pd.read_pickle(dataset)  # Load dataset\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{dataset} not found, loading from .json.bz2\")\n",
    "        complete_df = load_df(dataset)\n",
    "\n",
    "    _, subset_df = extract_subset(complete_df)\n",
    "    subset_df.to_pickle(os.path.join(\"data\", \"pkl\", f\"extracted_{dataset}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1264.36it/s]\n",
      "100%|██████████| 10000/10000 [00:07<00:00, 1307.20it/s]\n"
     ]
    }
   ],
   "source": [
    "year = 2008\n",
    "files = get_pkl_year(year)\n",
    "\n",
    "# Extract the quotes of interest of each chunk\n",
    "all_extracted = []\n",
    "for file in files:\n",
    "    df = pd.read_pickle(os.path.join(PKL_PATH, file))\n",
    "    _, subset_df = extract_subset(df)\n",
    "    all_extracted.append(subset_df)\n",
    "\n",
    "# Merge them into a new df\n",
    "df_extracted = pd.concat(all_extracted)\n",
    "\n",
    "# Save the df as pkl\n",
    "pkl_name = f\"extracted-quotes-{year}.pkl\"\n",
    "df_extracted.to_pickle(os.path.join(PKL_PATH, pkl_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_extracted = pd.read_pickle(os.path.join(PKL_PATH, \"extracted-quotes-2016.pkl\"))\n",
    "df2 = pd.read_pickle(os.path.join(PKL_PATH, \"2016\", \"quotes-2016-26.pkl\"))\n",
    "df2 = df2.sample(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ae8b51d14b46b6a71c95025e9e1db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=12500), Label(value='0 / 12500')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length, df2_extracted2 = extract_subset(df2, multiproc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1778"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6afe1dc6d4d3cd304b95f6d675ef2d0511325e35f0283dd46abd30ad807ae0f6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
