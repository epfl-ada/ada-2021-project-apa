{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "This notebook describes the sentiment analysis steps that were undertaken. In the first part, we extract the sentiment of each quotes. In the second, we provide some descriptive statistics of the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbc25a-a8f4-41c7-898e-5bbca37bd412",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476725bc-31a1-4be4-a8b4-3a70fb217ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import os\n",
    "\n",
    "# Third parties\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e4e51bc-e051-4b16-99dc-2b3dda281030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\olivi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initialization needed for some modules\n",
    "\n",
    "# tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# NLTK configuration\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f4c234-ac9a-4124-a21c-87fc301e6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data\"\n",
    "PKL_PATH = os.path.join(DATA_PATH, \"pkl\")\n",
    "CSV_PATH = os.path.join(DATA_PATH, \"csv\")\n",
    "RESOURCES_PATH = os.path.join(DATA_PATH, \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0449d4-c122-45cc-a9c7-95eb60883343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions\n",
    "\n",
    "def get_sentiment(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute the sentiment score of a given row\n",
    "    \"\"\"   \n",
    "    \n",
    "    row['NLTK_score'] = sia.polarity_scores(row['quotation'])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute sentiment score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have all our extracted mentions dataset, we will simply load each year and create a final aggregated dataframe, since it is not too big (around 100k quotes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "\n",
    "mentions = [os.path.join(CSV_PATH, f\"20{i:02d}_mentions.csv\") for i in range(15, 21)]  \n",
    "\n",
    "for mention in mentions:\n",
    "    df_mention = pd.read_csv(mention)\n",
    "    df_lst.append(df_mention)\n",
    "\n",
    "# Concatenate every year together\n",
    "df = pd.concat(df_lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105929/105929 [01:35<00:00, 1111.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute the sentiment score\n",
    "df = df.progress_apply(get_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the computed score is json formatted, we will extract every key of that column and create a new column in the dataset for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105929/105929 [00:23<00:00, 4595.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split in columns to get values \n",
    "df = pd.concat([df, df['NLTK_score'].progress_apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "      <th>subset</th>\n",
       "      <th>...</th>\n",
       "      <th>honorificSuffix</th>\n",
       "      <th>fullName</th>\n",
       "      <th>position</th>\n",
       "      <th>stateName</th>\n",
       "      <th>parties</th>\n",
       "      <th>NLTK_score</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8830</th>\n",
       "      <td>2017-03-08-013119</td>\n",
       "      <td>as secret as donald trump's tax returns.</td>\n",
       "      <td>lloyd doggett</td>\n",
       "      <td>['Q363817']</td>\n",
       "      <td>2017-03-08 11:30:10</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[['Lloyd Doggett', '0.8057'], ['None', '0.1471...</td>\n",
       "      <td>['http://gantdaily.com/2017/03/08/house-begins...</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Representative</td>\n",
       "      <td>TX</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>2015-11-06-032532</td>\n",
       "      <td>i am disappointed the president today rejected...</td>\n",
       "      <td>kelly ayotte</td>\n",
       "      <td>['Q22354']</td>\n",
       "      <td>2015-11-06 07:25:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[['Kelly Ayotte', '0.6593'], ['None', '0.2289'...</td>\n",
       "      <td>['http://www.wmur.com/politics/hassan-supports...</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kelly ayotte</td>\n",
       "      <td>Senator</td>\n",
       "      <td>NH</td>\n",
       "      <td>Republican</td>\n",
       "      <td>{'neg': 0.068, 'neu': 0.698, 'pos': 0.234, 'co...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.9382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 quoteID                                          quotation  \\\n",
       "8830   2017-03-08-013119           as secret as donald trump's tax returns.   \n",
       "10565  2015-11-06-032532  i am disappointed the president today rejected...   \n",
       "\n",
       "             speaker         qids                 date  numOccurrences  \\\n",
       "8830   lloyd doggett  ['Q363817']  2017-03-08 11:30:10            28.0   \n",
       "10565   kelly ayotte   ['Q22354']  2015-11-06 07:25:30             1.0   \n",
       "\n",
       "                                                  probas  \\\n",
       "8830   [['Lloyd Doggett', '0.8057'], ['None', '0.1471...   \n",
       "10565  [['Kelly Ayotte', '0.6593'], ['None', '0.2289'...   \n",
       "\n",
       "                                                    urls phase  subset  ...  \\\n",
       "8830   ['http://gantdaily.com/2017/03/08/house-begins...     E    True  ...   \n",
       "10565  ['http://www.wmur.com/politics/hassan-supports...     E    True  ...   \n",
       "\n",
       "      honorificSuffix      fullName        position stateName     parties  \\\n",
       "8830               II           NaN  Representative        TX    Democrat   \n",
       "10565             NaN  kelly ayotte         Senator        NH  Republican   \n",
       "\n",
       "                                              NLTK_score    neg    neu    pos  \\\n",
       "8830   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.000  1.000  0.000   \n",
       "10565  {'neg': 0.068, 'neu': 0.698, 'pos': 0.234, 'co...  0.068  0.698  0.234   \n",
       "\n",
       "      compound  \n",
       "8830    0.0000  \n",
       "10565   0.9382  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final dataframe both in csv and pickle\n",
    "df.to_pickle(os.path.join(PKL_PATH, \"final_subset.pkl\"))\n",
    "df.to_csv(os.path.join(CSV_PATH, \"final_subset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our final subset, we can conduct our exploratory data analysis on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment analysis\n",
    "\n",
    "We will now perform some preliminary analysis, having in mind that we want to analyze the evolution of the sentiment scores accross time. In the first section, we will present some basic descriptive statistics about the data we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid running the above cells, we load the dataframe directly\n",
    "# either from csv or pickle\n",
    "df = pd.read_pickle(os.path.join(PKL_PATH, \"final_subset.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df by party\n",
    "df_rep = df[df[\"parties\"] == \"Republican\"]\n",
    "df_dem = df[df[\"parties\"] == \"Democrat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_rep)=56257\n",
      "len(df_dem)=49672\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(df_rep)=}\")\n",
    "print(f\"{len(df_dem)=}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edc1a23f945431ce4c0ce12a191555bee6d7f0d3bb9235137bba8922e6ad584d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
