{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "This notebook describes the sentiment analysis steps that were undertaken. In the first part, we extract the sentiment of each quotes. In the second, we provide some descriptive statistics of the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbc25a-a8f4-41c7-898e-5bbca37bd412",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476725bc-31a1-4be4-a8b4-3a70fb217ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Third parties\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4e51bc-e051-4b16-99dc-2b3dda281030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\olivi\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Initialization needed for some modules\n",
    "\n",
    "# tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# NLTK configuration\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f4c234-ac9a-4124-a21c-87fc301e6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data\"\n",
    "PKL_PATH = os.path.join(DATA_PATH, \"pkl\")\n",
    "CSV_PATH = os.path.join(DATA_PATH, \"csv\")\n",
    "RESOURCES_PATH = os.path.join(DATA_PATH, \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0449d4-c122-45cc-a9c7-95eb60883343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions\n",
    "\n",
    "def get_sentiment(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute the sentiment score of a given row\n",
    "    \"\"\"   \n",
    "    \n",
    "    row['NLTK score'] = sia.polarity_scores(row['quotation'])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute sentiment score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have all our extracted mentions dataset, we will simply load each year and create a final aggregated dataframe, since it is not too big (around 100k quotes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "\n",
    "mentions = [os.path.join(CSV_PATH, f\"20{i:02d}_mentions.csv\") for i in range(15, 21)]  \n",
    "\n",
    "for mention in mentions:\n",
    "    df_mention = pd.read_csv(mention)\n",
    "    df_lst.append(df_mention)\n",
    "\n",
    "# Concatenate every year together\n",
    "df = pd.concat(df_lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105929/105929 [00:47<00:00, 2225.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute the sentiment score\n",
    "df = df.progress_apply(get_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the computed score is json formatted, we will extract every key of that column and create a new column in the dataset for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105929/105929 [00:23<00:00, 4533.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split in columns to get values \n",
    "df = pd.concat([df, df['NLTK score'].progress_apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "      <th>...</th>\n",
       "      <th>parties</th>\n",
       "      <th>NLTK score</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>199559</td>\n",
       "      <td>2015-02-25-111879</td>\n",
       "      <td>whether you are talking to a member of the hou...</td>\n",
       "      <td>john mchugh</td>\n",
       "      <td>['Q6247887', 'Q6247891']</td>\n",
       "      <td>2015-02-25 17:00:45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[['John McHugh', '0.6448'], ['None', '0.3552']]</td>\n",
       "      <td>['http://www.nationaldefensemagazine.org/_layo...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.847, 'pos': 0.153, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.8042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13718</th>\n",
       "      <td>85344</td>\n",
       "      <td>2017-08-23-163100</td>\n",
       "      <td>we're closely following the terrible events un...</td>\n",
       "      <td>president donald trump</td>\n",
       "      <td>['Q22686']</td>\n",
       "      <td>2017-08-23 08:58:44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[['President Donald Trump', '0.6922'], ['None'...</td>\n",
       "      <td>['http://www.politifact.com/truth-o-meter/arti...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>{'neg': 0.169, 'neu': 0.69, 'pos': 0.141, 'com...</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.7184</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.7184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0            quoteID  \\\n",
       "7983       199559  2015-02-25-111879   \n",
       "13718       85344  2017-08-23-163100   \n",
       "\n",
       "                                               quotation  \\\n",
       "7983   whether you are talking to a member of the hou...   \n",
       "13718  we're closely following the terrible events un...   \n",
       "\n",
       "                      speaker                      qids                 date  \\\n",
       "7983              john mchugh  ['Q6247887', 'Q6247891']  2015-02-25 17:00:45   \n",
       "13718  president donald trump                ['Q22686']  2017-08-23 08:58:44   \n",
       "\n",
       "       numOccurrences                                             probas  \\\n",
       "7983              2.0    [['John McHugh', '0.6448'], ['None', '0.3552']]   \n",
       "13718             2.0  [['President Donald Trump', '0.6922'], ['None'...   \n",
       "\n",
       "                                                    urls phase  ...  \\\n",
       "7983   ['http://www.nationaldefensemagazine.org/_layo...     E  ...   \n",
       "13718  ['http://www.politifact.com/truth-o-meter/arti...     E  ...   \n",
       "\n",
       "          parties                                         NLTK score    neg  \\\n",
       "7983   Republican  {'neg': 0.0, 'neu': 0.847, 'pos': 0.153, 'comp...  0.000   \n",
       "13718  Republican  {'neg': 0.169, 'neu': 0.69, 'pos': 0.141, 'com...  0.169   \n",
       "\n",
       "         neu    pos compound    neg    neu    pos compound  \n",
       "7983   0.847  0.153   0.8042  0.000  0.847  0.153   0.8042  \n",
       "13718  0.690  0.141  -0.7184  0.169  0.690  0.141  -0.7184  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final dataframe both in csv and pickle\n",
    "df.to_pickle(os.path.join(PKL_PATH, \"final_subset.pkl\"))\n",
    "df.to_csv(os.path.join(CSV_PATH, \"final_subset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our final subset, we can conduct our exploratory data analysis on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "Blabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df by party\n",
    "df_rep = df[df[\"parties\"] == \"Republican\"]\n",
    "df_dem = df[df[\"parties\"] == \"Democrat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_rep)=56257\n",
      "len(df_dem)=49672\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(df_rep)=}\")\n",
    "print(f\"{len(df_dem)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edc1a23f945431ce4c0ce12a191555bee6d7f0d3bb9235137bba8922e6ad584d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
